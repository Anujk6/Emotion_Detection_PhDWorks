# -*- coding: utf-8 -*-
"""Emotion_Analysis_USing_ML_Malayalam_NewDataset.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18XmQoL7Vz_BQ6CDZr_gw6EInmBiNHhkE
"""

! python

!pip -q install simpletransformers
!pip -q install xgboost

import pandas as pd
import torch
from simpletransformers.language_representation import RepresentationModel
from sklearn.linear_model import LogisticRegression
from sklearn.utils.class_weight import compute_class_weight
from sklearn.model_selection import GridSearchCV
import numpy as np
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import classification_report
from sklearn.metrics import f1_score
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.neural_network import MLPClassifier

#df = pd.read_csv('Kaggle_Mal_train.csv',sep='\t',header=None)
#df_test = pd.read_csv('Kaggle_Mal_test.csv',sep='\t',header=None)
#df_eval = pd.read_csv('Kaggle_Mal_val.csv',sep='\t',header=None)

df = pd.read_csv('New_Maltrain_data.csv',sep='\t',header=None)
df_test = pd.read_csv('New_Maltest_data.csv',sep='\t',header=None)
df_eval = pd.read_csv('New_Malval_data.csv',sep='\t',header=None)

df.rename(columns={0:'text',1:'category'},inplace=True)
df_test.rename(columns={0:'text',1:'category'},inplace=True)
df_test = df_test[['text','category']]
df_eval.rename(columns={0:'text',1:'category'},inplace=True)
df_eval = df_eval[['text','category']]

df_eval.category

num_labels = len(df['category'].unique())
keys = list(df['category'].unique())
values = list(range(0, num_labels))
label_dict = dict(zip(keys,values))
df['category'] = df['category'].apply(lambda x:label_dict[x])
df_test['category'] = df_test['category'].apply(lambda x:label_dict[x])
df_eval['category'] = df_eval['category'].apply(lambda x:label_dict[x])

num_labels

df_test = df_test.dropna()
df_test = df_test.reset_index().drop(['index'],axis=1)

"""ENCODINGS USING BERT"""

model = RepresentationModel(
        model_type="bert",
        model_name="bert-base-multilingual-cased",
        use_cuda=True
    )

train_sentence_vectors = model.encode_sentences(df['text'].to_list(), combine_strategy="mean")

print(train_sentence_vectors)

eval_sentences = df_eval['text'].to_list()
eval_sentence_vectors = model.encode_sentences(eval_sentences, combine_strategy="mean")

print(eval_sentence_vectors)

test_sentences = df_test['text'].to_list()
test_sentence_vectors = model.encode_sentences(test_sentences, combine_strategy="mean")

print(test_sentence_vectors)

train_sentence_vectors.shape

test_sentence_vectors.shape

eval_sentence_vectors.shape

"""Model Training

LOGISTIC REGRESSION
"""

import warnings
warnings.simplefilter(action='ignore', category=FutureWarning)

combined_df = pd.concat([df,df_eval],ignore_index=True)

combined_encodings = np.concatenate((train_sentence_vectors, eval_sentence_vectors))
combined_encodings.shape

#import warnings
 #warnings.filterwarnings('ignore')
 #parameters = {
     #'C'       : np.logspace(-3,3,7),
     #'solver'  : ['newton-cg', 'lbfgs', 'liblinear']
 #}

 #logreg = LogisticRegression()
#clf = GridSearchCV(logreg,
                   # param_grid = parameters,
                    #scoring='f1_macro',
                  # cv=10)
 #clf.fit(combined_encodings,combined_df['category'].to_list())
 #print("Tuned Hyperparameters :", clf.best_params_)
 #print("Weighted f1_score :",clf.best_score_)

"""MODEL TRAINING"""

class_weights = compute_class_weight(
    class_weight="balanced",
    classes=df['category'].unique(), # Removed the list() call
    y=df['category'].to_list()
)

keys = range(6) # unique 8 categories hence
values = class_weights
weights = dict(zip(keys,values))

lm = LogisticRegression(C=0.005,multi_class='ovr', solver='liblinear',class_weight=weights)
lm.fit(train_sentence_vectors, df['category'].to_list())

log_test_preds = lm.predict(test_sentence_vectors)

report_log = classification_report(df_test['category'].to_list(),log_test_preds,output_dict=True)

df_log = pd.DataFrame(report_log).transpose()
df_log

"""Decision Trees
Grid Search CV
"""

#warnings.filterwarnings('ignore')
#params = {'max_leaf_nodes': list(range(2, 100)), 'min_samples_split': [2, 3, 4]}
 #grid_search_cv = GridSearchCV(DecisionTreeClassifier(random_state=42), params, scoring='f1_macro',verbose=1, cv=5)
 #grid_search_cv.fit(combined_encodings,combined_df['category'].to_list())
#print("Tuned Hyperparameters :", grid_search_cv.best_params_)
 #print("Weighted f1_score :",grid_search_cv.best_score_)

"""MODEL TRAINING"""

dtree_model = DecisionTreeClassifier().fit(train_sentence_vectors, df['category'].to_list())

tree_preds = dtree_model.predict(test_sentence_vectors)
report = classification_report(df_test['category'].to_list(),tree_preds,output_dict=True)
final_report = pd.DataFrame(report).transpose()
final_report

"""SVC"""

# param_grid = {'C': [0.1, 1, 10, 100, 1000],
#               'gamma': [1, 0.1, 0.01, 0.001, 0.0001],
#               'kernel': ['rbf','linear','poly','sigmoid']}
# grid = GridSearchCV(SVC(), param_grid, scoring='f1_macro',cv=5)
# grid.fit(combined_encodings,combined_df['category'].to_list())
# print("Tuned Hyperparameters :", grid.best_params_)
# print("Weighted f1_score :",grid.best_score_)

"""MODEL TRAINING"""

svm = SVC(kernel='linear').fit(train_sentence_vectors,df['category'].to_list())

svm = SVC(kernel='linear').fit(train_sentence_vectors,df['category'].to_list())

svm_preds = svm.predict(test_sentence_vectors)
svm_report = classification_report(df_test['category'].to_list(),svm_preds,output_dict=True)
svm_report = pd.DataFrame(svm_report).transpose()
svm_report

"""RANDOM FOREST"""

# # Number of trees in random forest
# n_estimators = [10,100,200,500,1000]
# # Number of features to consider at every split
# max_features = ['auto', 'sqrt']
# bootstrap = [True, False]

# param_grid = {'n_estimators': n_estimators,
#                'max_features': max_features,
#                'bootstrap': bootstrap}
# grid = GridSearchCV(RandomForestClassifier(), param_grid, scoring='f1_macro',cv=2)
# grid.fit(combined_encodings,combined_df['category'].to_list())
# print("Tuned Hyperparameters :", grid.best_params_)
# print("Weighted f1_score :",grid.best_score_)

rf_params = {'bootstrap': False, 'max_features': 'sqrt', 'n_estimators': 100}
random_clf = RandomForestClassifier().fit(train_sentence_vectors, df['category'].to_list())

random_pred = random_clf.predict(test_sentence_vectors)
report_random = classification_report(df_test['category'].to_list(),random_pred,output_dict=True)
df_random = pd.DataFrame(report_random).transpose()
df_random

"""XGBoost"""

# xg_grid_params = {
#     'gamma': range(0,100,20),
#     'max_depth': [1,5,10],
#     'lambda':[0.01,0.1,1,10,100],
#     'alpha':[0.001,0.01,0.1,1,10],
#     'learning_rate':[0.01,0.1,1,10]
# }
# warnings.filterwarnings('ignore')
# grid_xg = grid = GridSearchCV(XGBClassifier(), xg_grid_params, scoring='f1_macro')
# grid_xg.fit(combined_encodings,combined_df['category'].to_list())
# print("Tuned Hyperparameters :", grid_xg.best_params_)
# print("Weighted f1_score :",grid_xg.best_score_)

##MODEL_TRAINING

model_xg = XGBClassifier().fit(train_sentence_vectors, df['category'].to_list())

y_preds_xg = model_xg.predict(test_sentence_vectors)
report_xg = classification_report(df_test['category'].to_list(),y_preds_xg,output_dict=True)
df_xg = pd.DataFrame(report_xg).transpose()
df_xg

"""Multilayer perceptron"""

# mlp_params = {
#     'activation':['identity', 'logistic', 'tanh', 'relu'],
#     'solver':['lbfgs', 'sgd', 'adam'],
#     'alpha':[0.0001,0.001,0.01,0.1],
# }
# warnings.filterwarnings('ignore')
# mlp_grid = GridSearchCV(MLPClassifier(), mlp_params, scoring='f1_macro')
# mlp_grid.fit(combined_encodings,combined_df['category'].to_list())
# print("Tuned Hyperparameters :", mlp_grid.best_params_)
# print("Weighted f1_score :",mlp_grid.best_score_)

clf = MLPClassifier().fit(train_sentence_vectors, df['category'].to_list())
mlp_predictions = clf.predict(test_sentence_vectors)

report_mlp = classification_report(df_test['category'].to_list(),mlp_predictions,output_dict=True)
df_mlp = pd.DataFrame(report_mlp).transpose()
df_mlp